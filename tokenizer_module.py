def custom_tokenizer(text):
    return text.split()  # Simple space-based tokenizer